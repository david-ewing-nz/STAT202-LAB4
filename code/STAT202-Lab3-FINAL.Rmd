---
title: "STAT202 Assignment 3: \nMultiple Linear Regression II"
author: "Your Name"
date: "Due on 14th August 2024"
output:
   word_document:
      reference_docx: "template.docx"
---

#Introduction

This document contains the analysis for Assignment 3. It explores the aquatic_toxicity dataset using multiple linear regression to understand the relationships between various predictors and the response variable LC50. 



# Step 0: setup

loading libraries:

```{r setup, include=TRUE}

set.seed(82171165)   #set seed 

knitr::opts_chunk$set(
  echo    = TRUE, # Show all code by default
  message = TRUE, # Include package messages
  warning = TRUE  # Include warnings if they occur
)



library(conflicted)
library(tidyverse)
library(readxl)
library(readr) 
library(performance)
library(GGally)
library(flextable)
library(broom)
library(skimr)
library(data.table)
library(lmtest)  
library(leaps)
conflict_prefer("filter", "dplyr"); conflict_prefer("select", "dplyr")

```

\newpage

# Step 2: Read aquatic_toxicity.xlsx

```{r step2, echo=TRUE, message=TRUE}
# Load the data
toxic <- read_excel("../data/aquatic_toxicity.xlsx")
```


# Step 3: Select a random sample of 500 rows

```{r step3, echo=TRUE, message=TRUE}
set.seed(82171165)

toxic_rows   <- nrow(toxic)
toxic_sample <- toxic |> slice_sample(n = 500) # without replacement
my_toxic     <- toxic_sample

# Summarise missing values 
# View the first few rows of the sample

skim_toxic <- skim(my_toxic) |>
  select(skim_variable, n_missing)
skim_toxic                           
head(toxic_sample)                   

 
```

\newpage

# Step 4: Estimate the correlations between all variables

```{r step4, echo=TRUE, message=TRUE}


# Calculate the correlation matrix
cors    <- cor(my_toxic, use = "complete.obs")  # Ensure complete observations
cors_3d <- round(cors, 3)                       # Round to 3 decimal places

# Convert the correlation matrix into a data frame and add row identifiers
cor_df <- as.data.frame(cors_3d)
cor_df <- tibble::rownames_to_column(cor_df, var = " ")  # Add var column

cor_table <- flextable(cor_df) %>%
  set_caption("Correlation Matrix of Variables in my_toxic (Rounded to 3 Decimal Places)") %>%
  bg(part = "header", bg = "#D3D3D3") %>%                # Add grey header
  bg(j = 1,           bg = "#D3D3D3", part = "all") %>%  # Add grey column
  theme_box() %>%
  autofit() %>%  #  adjust column widths
  align(j = 1, align = "left", part = "all")  # Align the first column (row identifiers) to the left
#cors
```


```{r}

cor_table

```



# Step 4+: Top variables to predict LC50

```{r step4pfix, echo=TRUE, message=FALSE, fig.width=8, fig.height=6}

# 3 variables with the highest correlation with LC50
lc50_sort <- sort(cors["lc50", ], decreasing = TRUE)
lc50_sort <- lc50_sort[lc50_sort != 1]
top_3     <- names(lc50_sort[1:3])

lc50_matrix <- my_toxic[, c(top_3, "lc50")] |>
  ggpairs(
    lower = list(continuous = wrap("smooth", method = "lm", se = TRUE)),
    title = "Scatterplot Matrix: 3 top variables to predict LC50\nwith Confidence Interval"
  ) +
  theme_bw()

```

\newpage

```{r }

lc50_matrix

```

------------------------------------------------------------------------

A positive correlation between **mlogp** and **LC50**; with weaker positive relationships for **rdchi** and **LC50**; and an insiginficatn association between **tpsa** and **LC50**. Each relationship appear generally linear but variability, particularly in **rdchi**, could affect predictability. THere has been no attempt to remove outliers.

------------------------------------------------------------------------

\newpage

# Step 5: multiple linear regression model to predict LC50

```{r step5, echo=TRUE, message=TRUE}

lc50_arg <- as.formula(paste("lc50 ~ ", paste(top_3, collapse = " + ")))
m1       <- lm(lc50_arg, data = my_toxic)
summary(m1)
tidy(m1)
```

------------------------------------------------------------------------

$$
LC50 = 2.6804 + 0.7416 \cdot \text{mlogp} - 0.2175 \cdot \text{rdchi} + 0.0159 \cdot \text{tpsa}
$$

------------------------------------------------------------------------

\newpage

# Step 6: Fit All Regression Subsets using adjusted R-squared

```{r Step 6 }

all_models <- regsubsets(lc50 ~ ., data = my_toxic)
plot(all_models, scale = "adjr2", 
     main = expression("Regression Subsets (Adjusted " ~ R^2 ~ ")"))
```

------------------------------------------------------------------------

Both mlogp and tpsa appear here and in the coorelation matrix as good and perhaps reliable predictors for LC50, however, saacc and nn are selected the regression subsets relative to adjusted r-squared. This suggest that while they may not be strong standalone predictors, they may reduce the variablility when added to combinations with other variables like mlogp.

------------------------------------------------------------------------

\newpage

# Step 7: Fit the Best Model and Compare

```{r Step7 }

# Fit the best model identified in Step 6
m2_arg1 <- lc50 ~ saacc + nn + mlogp  # Based on the best subset from Step 6
m2        <- lm(m2_arg1, data = my_toxic)

# Summary of the best model
summary(m2)
```

```{r , echo=FALSE}
# Compare Adjusted R² and Residual Standard Error with Step 5 model
m1_adjr2 <- summary(m1)$adj.r.squared
m1_rse    <- summary(m1)$sigma

m2_adjr2 <- summary(m2)$adj.r.squared
m1_rse    <- summary(m2)$sigma

# Create a dataframe for comparison
comparison_df <- data.frame(
  Metric = c("Adjusted R²", "Residual SE"),
  `m1` = c(round(m1_adjr2, 4), round(m2_adjr2, 4)),
  `m2` = c(round(m2_adjr2, 4), round(m1_rse, 4))
)



comparison_table <- flextable(comparison_df) %>%
  set_caption("Comparison of Regression Models: Step 5 vs Step 7") %>%
  bg(part = "header", bg = "#D3D3D3") %>%  # Grey header
  theme_box() %>%  #  border styling
  align(j = 1,   align = "left", part = "all") %>%  # Left-align Metric column
  align(j = 2:3, align = "center", part = "all") %>%  # Centre-align model columns
  border_inner_v(part = "all") %>%  #  vertical 
  border_inner_h(part = "all") %>%  #  horizontal 
  border_outer(part = "all") %>%    #  outer 
  autofit()  

# Display the table
comparison_table

```

------------------------------------------------------------------------

While m2 includes saacc and nn, which may reduce multicollinearity, it does not outperform m1 in terms of predictive power or error minimisation. m1 has a higher adjusted r-square indicating that it explains more vaariance of LC50 than m2. The residule SE for m1 is significantly lower than m2 meaning that m1 provides a more precise model of LC50 than m2.

------------------------------------------------------------------------

\newpage

# Step8: Diagnostic Plots for Model Residuals and to Check Assumptions

```{r Step8, fig.width = 7, fig.height = 5}

check_model(m2)

m2_residuals <- residuals(m2) 
```

```{r ,echo=FALSE}

metrics_df <- data.frame(
  Metric = c(
    "Linearity",
    "Homoscedasticity",
    "Normality of Residuals",
    "Influential Observations",
    "Collinearity",
    "Posterior Predictive Check"
  ),
  Assumption_Met = c(
    "No, deviations from linearity in the Residuals vs Fitted plot.",
    "No, increasing variance of residuals indicates heteroscedasticity.",
    "No, Q-Q plot shows deviations from normality at the tails.",
    "No, some influential points (e.g., 388, 258) are identified.",
    "Yes, VIF values are below 5, indicating low multicollinearity..",
    "Yes, reasonable alignment."
  )
)


metrics_table <- flextable(metrics_df) %>%
  set_caption("Diagnostic Metrics and Assumption Validation") %>%
  bg(part = "header", bg = "#D3D3D3") %>%  # Grey header
  theme_box() %>%
  align(j = 1, align = "left", part = "all") %>%  # Left-align Metric column
  align(j = 2, align = "left", part = "all") %>%  # Left-align Assumption_Met column
  border_inner_v(part = "all") %>%  # Add vertical borders
  border_inner_h(part = "all") %>%  # Add horizontal borders
  border_outer(part = "all") %>%    # Add outer borders
  autofit()  # Automatically fit content
```

\newpage

```{r , echo=FALSE}
# Display the table
metrics_table


```

------------------------------------------------------------------------

The posterior predictive check shows reasonable alignment between the model-predicted LC50 and observed data. The Residuals vs Fitted Values plot indicates curvature, suggesting potential non-linearity in the predictor-response relationships. The Scale-Location plot shows increasing residual variance as fitted values increase, discrediting the assumption of homoscedasticity. Influential observations, such as points 388 and 258, are flagged as close to the Cook’s distance lines and may disproportionately influence the model. The Variance Inflation Factor (VIF) values for the predictors (mlogp, nn, saacc) are all below 5, indicating low multicollinearity and stability. The Q-Q plot shows deviations from the normal at the tails, suggesting that residuals are not perfectly normally distributed.

------------------------------------------------------------------------

# Step 9: Predict LC50 with Confidence and Prediction Intervals


```{r Step9}
# Step 9: Predict LC50 with Confidence and Prediction Intervals

# Create tibble of specified characteristics
new_chemicals <- tibble(
  tpsa   = c(69.97, 3.24),
  saacc  = c(97.43, 3.12),
  h_050  = c(0,     0),
  mlogp  = c(3.12,  9.15),
  rdchi  = c(3.72,  5.49),
  gats1p = c(1.26,  1.56),
  nn     = c(0,     1),
  c_040  = c(2,     0)
)

# Generate predictions with confidence intervals
confidence_predictions <- predict(
  m1, 
  newdata = new_chemicals, 
  interval = "confidence", 
  level = 0.95
)

# Generate predictions with prediction intervals
prediction_predictions <- predict(
  m1, 
  newdata = new_chemicals, 
  interval = "prediction", 
  level = 0.95
)

# Combine the results into a single tibble
predicted_chemicals <- new_chemicals %>%
  mutate(
    Predicted_LC50 = confidence_predictions[, "fit"],
    Lwr_Confidence = confidence_predictions[, "lwr"],
    Upr_Confidence = confidence_predictions[, "upr"],
    Lwr_Prediction = prediction_predictions[, "lwr"],
    Upr_Prediction = prediction_predictions[, "upr"]
  )

# Create a table summarising predictions for display
simple_table <- tibble(
  Chemical = c("Chemical 1", "Chemical 2"),
  `Predicted LC50` = round(confidence_predictions[, "fit"], 3),
  `Lwr Confidence` = round(confidence_predictions[, "lwr"], 3),
  `Upr Confidence` = round(confidence_predictions[, "upr"], 3),
  `Lwr Prediction` = round(prediction_predictions[, "lwr"], 3),
  `Upr Prediction` = round(prediction_predictions[, "upr"], 3)
)

# Display the table using flextable
library(flextable)

flextable(simple_table) %>%
  set_caption("Predicted LC50 with 95% Confidence and Prediction Intervals") %>%
  bg(part = "header", bg = "#D3D3D3") %>%
  theme_box() %>%
  align(j = 1, align = "left", part = "all") %>%
  align(j = 2:6, align = "center", part = "all") %>%
  autofit()

```



# Step 10: Compare Regression Subsets with Different Scales

```{r Step10 }


# Step 10: Compare Regression Subsets with Different Scales

# Plot using adjusted R²
plot(all_models, scale = "adjr2", 
     main = expression("Regression Subsets (Adjusted " ~ R^2 ~ ")"))

# Plot using R²
plot(all_models, scale = "r2", 
     main = expression("Regression Subsets (" ~ R^2 ~ ")"))

# Plot using BIC
plot(all_models, scale = "bic", 
     main = "Regression Subsets (Bayesian Information Criterion)")

```
```{r}

# Create a summary table of selected models
model_summary <- tibble(
  Criterion = c("Adjusted R²", "R²", "BIC"),
  `Selected Model` = c(
    "lc50 ~ mlogp + nn + saacc",                # Adjusted R² model
    "lc50 ~ mlogp + nn + saacc + tpsa + rdchi", # R² model
    "lc50 ~ mlogp + saacc"                      # BIC model
  ),
  Explanation = c(
    "Balances fit and simplicity.",
    "Maximises variance explained\nbut may overfit.",
    "Prioritises simplicity and\navoids overfitting."
  )
)

# Use flextable to format and display the table
library(flextable)

flextable(model_summary) %>%
  set_caption("Comparison of Models Selected by Adjusted R², R², and BIC") %>%
  bg(part = "header", bg = "#D3D3D3") %>%
  theme_box() %>%
  align(j = 1:3, align = "left", part = "all") %>%
  autofit()


```

---


Adjusted r-square selects a balanced model with moderate predictors, optimising fit while penalising complexity. r-square  prioritises explaining variance, often favouring larger models and risk overfitting. BIC heavily penalises model complexity, selecting simpler models. 
  
---

\newpage

# Step 11: Reproduce Regression Coefficients for m2 using Matrix Algebra

```{r}


X <- model.matrix(m2)

y <- my_toxic %>% pull(lc50)  # Extract lc50 column as a vector


coefficients_m2 <- solve(t(X) %*% X) %*% t(X) %*% y # regression coefficients 
lm_coefficients <- coef(m2)

# Combine the results into a tibble for comparison
comparison_df <- tibble(
  Predictor = names(lm_coefficients),
  `Matrix Algebra Coefficients` = as.vector(coefficients_m2),
  `lm() Coefficients` = lm_coefficients
)

comparison_table <- flextable(comparison_df) %>%
  set_caption("Comparison of Regression Coefficients: Matrix Algebra vs lm()") %>%
  bg(part = "header", bg = "#D3D3D3") %>%
  theme_box() %>%
  align(j = 1, align = "left", part = "all") %>%  # Left-align Predictor column
  align(j = 2:3, align = "center", part = "all") %>%  # Center-align coefficient columns
  border_inner_v(part = "all") %>%
  border_inner_h(part = "all") %>%
  border_outer(part = "all") %>%
  autofit()

# Display the table
comparison_table


```


  